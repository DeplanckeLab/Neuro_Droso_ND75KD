{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1be40436-cba2-40e5-8a2b-16a755a2af67",
   "metadata": {},
   "source": [
    "# Jeffries Human Brain Aging - pySCENIC pipeline (Embedded version)\n",
    "\n",
    "**Author:** Vincent Gardeux\n",
    "\n",
    "**Date Created:** 2025-11-17\n",
    "\n",
    "**Date Modified:** 2025-11-21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73ed30e6-577c-4399-a223-5c15e257f1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix OPENBLAS Warnings\n",
    "import os\n",
    "param_n_workers = 24 # We have 112 CPUs/cores, each process will automatically be associated to a different CPU by the OS scheduler\n",
    "param_threads_per_worker=1 # We have 2 threads per CPU on SVEN (hyper-threading). See lscpu command. Note: Here they are not used apparently. Setting to 1 or 2 gives similar c. time\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = f\"{param_n_workers * param_threads_per_worker}\"\n",
    "os.environ['MKL_NUM_THREADS'] = f\"{param_n_workers * param_threads_per_worker}\"\n",
    "os.environ['OMP_NUM_THREADS'] = f\"{param_n_workers * param_threads_per_worker}\"\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = f\"{param_n_workers * param_threads_per_worker}\"\n",
    "\n",
    "# import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "import regdiffusion as rd # For replacing grnboost2 which is slow as hell and bugs (stalls) when there are more than ~1.5B elements in the matrix\n",
    "import ast # For reading frozenset as strings\n",
    "import pickle\n",
    "import pytz\n",
    "\n",
    "from datetime import datetime\n",
    "from arboreto.utils import load_tf_names\n",
    "from arboreto.algo import grnboost2\n",
    "from distributed import Client, LocalCluster\n",
    "\n",
    "from ctxcore.rnkdb import FeatherRankingDatabase as RankingDatabase\n",
    "from pyscenic.binarization import binarize\n",
    "from pyscenic.utils import modules_from_adjacencies\n",
    "from pyscenic.prune import prune2df, df2regulons\n",
    "from pyscenic.aucell import aucell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05d8c812-a556-4b77-89da-953814a2140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Input] H5ad file to use\n",
    "EXPRESSION_H5AD_FNAME = '/data/gardeux/Neuro_Droso_ND75KD/data/Jeffries_2025_HumanBrainAging/pfc.clean.h5ad' # Built from pfc.clean.rds. Downloaded from https://publications.wenglab.org/SomaMut/Jeffries_Yu_BrainAging_2025/\n",
    "\n",
    "# [Input] Transcription factors list (SCENIC step 1: GRNBoost2)\n",
    "f_tfs = \"/data/gardeux/Neuro_Droso_ND75KD/data/allTFs_hg38.txt\" # From https://resources.aertslab.org/cistarget/tf_lists/\n",
    "# Derive list of Transcription Factors(TF)\n",
    "tf_names = load_tf_names(f_tfs)\n",
    "\n",
    "# [Output] Adjacency matrix (SCENIC step 1: GRNBoost2)\n",
    "adj_matrix = \"/data/gardeux/Neuro_Droso_ND75KD/data/Jeffries_2025_HumanBrainAging/pySCENIC/Jeffries_HBAging_adj.csv\"\n",
    "\n",
    "# [Input] Ranking databases (SCENIC step 2-3: cisTarget)\n",
    "f_db_names = [\"/data/gardeux/Neuro_Droso_ND75KD/data/hg38_500bp_up_100bp_down_full_tx_v10_clust.genes_vs_motifs.rankings.feather\", \"/data/gardeux/Neuro_Droso_ND75KD/data/hg38_10kbp_up_10kbp_down_full_tx_v10_clust.genes_vs_motifs.rankings.feather\"] # From pySCENIC db: https://resources.aertslab.org/cistarget/databases/homo_sapiens/hg38/refseq_r80/mc_v10_clust/gene_based/\n",
    "dbs = [RankingDatabase(fname=f_name, name=os.path.basename(f_name)) for f_name in f_db_names]\n",
    "\n",
    "# [Input] Motif databases (SCENIC step 2-3: cisTarget)\n",
    "f_motif_path = \"/data/gardeux/Neuro_Droso_ND75KD/data/motifs-v10nr_clust-nr.hgnc-m0.001-o0.0.tbl\" # From pySCENIC db: https://resources.aertslab.org/cistarget/motif2tf/\n",
    "\n",
    "# [Output] Regulons (SCENIC step 2-3: cisTarget)\n",
    "f_motifs_path = \"/data/gardeux/Neuro_Droso_ND75KD/data/Jeffries_2025_HumanBrainAging/pySCENIC/Jeffries_HBAging_motifs.tsv\"\n",
    "f_modules_pickle = \"/data/gardeux/Neuro_Droso_ND75KD/data/Jeffries_2025_HumanBrainAging/pySCENIC/Jeffries_HBAging_modules.pkl\"\n",
    "f_modules_path = \"/data/gardeux/Neuro_Droso_ND75KD/data/Jeffries_2025_HumanBrainAging/pySCENIC/Jeffries_HBAging_modules.tsv\"\n",
    "f_regulons_path = \"/data/gardeux/Neuro_Droso_ND75KD/data/Jeffries_2025_HumanBrainAging/pySCENIC/Jeffries_HBAging_regulons.tsv\"\n",
    "f_regulons_pickle = \"/data/gardeux/Neuro_Droso_ND75KD/data/Jeffries_2025_HumanBrainAging/pySCENIC/Jeffries_HBAging_regulons.pkl\"\n",
    "f_regulons_aucell_path = \"/data/gardeux/Neuro_Droso_ND75KD/data/Jeffries_2025_HumanBrainAging/pySCENIC/Jeffries_HBAging_regulons_aucell.tsv\"\n",
    "f_regulons_binarized_aucell_path = \"/data/gardeux/Neuro_Droso_ND75KD/data/Jeffries_2025_HumanBrainAging/pySCENIC/Jeffries_HBAging_regulons_aucell_binarized.tsv\"\n",
    "f_regulons_binarization_thresholds_aucell_path = \"/data/gardeux/Neuro_Droso_ND75KD/data/Jeffries_2025_HumanBrainAging/pySCENIC/Jeffries_HBAging_regulons_aucell_binarization_thresholds.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90accdd5-78fa-4b1a-8920-86247309aa71",
   "metadata": {},
   "source": [
    "Load ex_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b482e26c-d845-4573-843e-bdca216e2f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Input] Load expression matrix from H5ad file\n",
    "f_h5ad = ad.read_h5ad(EXPRESSION_H5AD_FNAME)\n",
    "f_gene_names = f_h5ad.var_names.tolist()  # Gene names\n",
    "f_cell_names = f_h5ad.obs_names.tolist()   # Cell names\n",
    "ex_matrix = pd.DataFrame.sparse.from_spmatrix(f_h5ad.X.T, index=f_gene_names, columns=f_cell_names)\n",
    "\n",
    "# Restrict matrix to feather genes\n",
    "ranking_feather = pd.read_feather(f_db_names[0])\n",
    "overlap_values = ex_matrix.index[pd.Series(ex_matrix.index).isin(ranking_feather.columns)].unique()\n",
    "ex_matrix = ex_matrix.loc[overlap_values, :] # This step takes forever\n",
    "\n",
    "ex_matrix # 18099 genes x 367317 cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75721439-c596-4c39-8c66-75649e07ee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safety check\n",
    "(f_h5ad.obs.index == ex_matrix.columns).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c74d7a8-96d7-4ab5-8d8e-750bac4e8e8f",
   "metadata": {},
   "source": [
    "# SCENIC steps\n",
    "\n",
    "## STEP 1: Gene regulatory network inference, and generation of co-expression modules\n",
    "\n",
    "### 1.a. GRN inference using the GRNBoost2 algorithm\n",
    "\n",
    "In the initial phase of the pySCENIC pipeline the single cell expression profiles are used to infer co-expression modules from.\n",
    "\n",
    "Run GRNboost from arboreto to infer co-expression modules\n",
    "\n",
    "The arboreto package is used for this phase of the pipeline.\n",
    "\n",
    "*Output:* List of adjacencies between a TF and its targets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c13c5f-be23-43ec-8896-429b8bde1c8e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Option 1:** Run GRNBoost2 algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1dcba0-03dd-4d67-857b-450d2b77aeac",
   "metadata": {},
   "source": [
    "```\n",
    "start = datetime.now(pytz.timezone('Europe/Paris'))\n",
    "print(\"Start time:\", start.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "# Prepare the multithreading\n",
    "cluster = LocalCluster(name='grn_call', dashboard_address=\":12345\", n_workers=param_n_workers, threads_per_worker=param_threads_per_worker)\n",
    "client = Client(cluster)\n",
    "\n",
    "# Here I run the function within the package (no CLI)\n",
    "adjacencies = grnboost2(expression_data=ex_matrix.transpose(), tf_names=tf_names, seed=42, verbose=True, client_or_address=client)\n",
    "            \n",
    "# Shutting down cluster\n",
    "client.close()\n",
    "cluster.close()\n",
    "    \n",
    "end = datetime.now(pytz.timezone('Europe/Paris'))\n",
    "print(\"End time:\", end.strftime(\"%H:%M:%S\"))\n",
    "print(\"Running time:\", (end - start))\n",
    "\n",
    "# Note: Takes ~50mn with n_workers=12, threads_per_worker=2 => With reduced matrix to overlapping genes between .feather file and our matrix\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece95add-bc40-47a0-8d6d-3932e364d60a",
   "metadata": {},
   "source": [
    "Here it stalls for several days at step \"creating dask graph\"...\n",
    "\n",
    "I think there is a bug in grnboost2 which makes it incompatible with big matrices i.e. impossible to deal with >~1.5B elements in the matrix. Here we have 6.6B...\n",
    "\n",
    "So I'll use regdiffusion instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66dd714-c8a7-42d1-9bc2-54e266ca314d",
   "metadata": {},
   "source": [
    "**Option 2:** Run regdiffusion specific code\n",
    "### * * REGDIFFUSION SPECIFIC CODE * * ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dd97c6-aab4-43af-8bcc-4410c15b2759",
   "metadata": {},
   "source": [
    "Run RegDiffusionTrainer instead of the (slow) GRNBoost2 algorithm. See https://tuftsbcb.github.io/RegDiffusion/downstream_with_pyscenic.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683e806e-0632-4947-b817-959f0d92a0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset for RegDiffusionTrainer (needs to be logged, cells as rows)\n",
    "ex_matrix_log = np.log(ex_matrix.transpose() + 1.0) # Transpose and log\n",
    "ex_matrix_log = ex_matrix_log.loc[:, ~(ex_matrix_log == 0).all()] # Drop columns where all values are 0\n",
    "ex_matrix_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e53b546-f324-4ab8-b3e8-95204160025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now(pytz.timezone('Europe/Paris'))\n",
    "print(\"Start time:\", start.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "rd_trainer = rd.RegDiffusionTrainer(ex_matrix_log.to_numpy(), device=\"cpu\")\n",
    "rd_trainer.train()\n",
    "\n",
    "end = datetime.now(pytz.timezone('Europe/Paris'))\n",
    "print(\"End time:\", end.strftime(\"%H:%M:%S\"))\n",
    "print(\"Running time:\", (end - start))\n",
    "\n",
    "# Note: Takes ~2h38 with n_workers=24, threads_per_worker=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6e1f0d-2262-4a37-b221-d7aaa50a5067",
   "metadata": {},
   "source": [
    "Extract edges from GRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ceb1d3-854b-4e42-a8e9-0b1540453232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we focus on edges with weight > 50 percentile. \n",
    "grn = rd_trainer.get_grn(ex_matrix_log.columns, top_gene_percentile = 50) # gene_names to recover non-expressed genes\n",
    "\n",
    "# Here for each gene, we are going to extract all edges\n",
    "adjacencies = grn.extract_edgelist(k = -1, workers = param_n_workers)\n",
    "adjacencies.columns = ['TF', 'target', 'importance']\n",
    "\n",
    "# check edgelist.  \n",
    "adjacencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b79138-b6b3-417c-bf86-462794b23ba5",
   "metadata": {},
   "source": [
    "Read in the adjacencies matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf41577c-0d74-4c83-9339-6c918dacc2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict to tf names\n",
    "adjacencies = adjacencies[adjacencies['TF'].isin(tf_names)]\n",
    "# Sort by importance\n",
    "adjacencies = adjacencies.sort_values(by='importance', ascending=False)\n",
    "adjacencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae842a1-e3dc-49b3-ae8a-16a57108141e",
   "metadata": {},
   "source": [
    "### * * / REGDIFFUSION SPECIFIC CODE * * ###\n",
    "\n",
    "Here is the end of the regdiffusion specific code. If grnboost2 worked, then you can resume here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20178be6-22dc-471b-bc15-e7d916bf7b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adjacencies.TF.nunique(), \"unique TF-modules were found ( out of\",len(tf_names),\").\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4862ac05-d4d4-4a02-808c-845e4a447582",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adjacencies.target.nunique(), \"unique targets were found ( out of\",len(ex_matrix.index),\").\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f331f3a0-63a4-46aa-978e-803238eec2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacencies.TF.isin(tf_names).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da47991",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacencies.to_csv(adj_matrix, index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812ef0b4-c6ea-4bcb-a51d-0af003581753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint to recover from file (eventually)\n",
    "#adjacencies = pd.read_csv(adj_matrix, sep=',', na_filter=False) # If na_filter=True, the nan gene is detected as NaN\n",
    "adjacencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bae0331-439e-4ba8-8487-ea92e73f5eb3",
   "metadata": {},
   "source": [
    "## STEP 2-3: Regulon prediction aka cisTarget\n",
    "\n",
    "*Output:* List of adjacencies between a TF and its targets.\n",
    "\n",
    "### 2.a. Running regulon prediction using cisTarget\n",
    "\n",
    "Here, we use the --mask_dropouts option, which affects how the correlation between TF and target genes is calculated during module creation. It is important to note that prior to pySCENIC v0.9.18, the default behavior was to mask dropouts, while in v0.9.18 and later, the correlation is performed using the entire set of cells (including those with zero expression). When using the modules_from_adjacencies function directly in python instead of via the command line, the rho_mask_dropouts option can be used to control this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a8b86f-231f-41a6-a79c-9267bcaa27a7",
   "metadata": {},
   "source": [
    "**Note:** In the following code, I use `rho_mask_dropouts=True` for keeping the old R behaviour. It also produces slightly more regulons.\n",
    "\n",
    "<span color=\"red\">**Issue:** This function `modules_from_adjacencies` is inherently bugged. As it's supposed to run on a single thread but bypass all my specifications to run on all available cores. I don't know how to fix this behaviour and for the function to limit the number of cores</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178d47d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now(pytz.timezone('Europe/Paris'))\n",
    "print(\"Start time:\", start.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "modules = list(modules_from_adjacencies(adjacencies, ex_matrix.transpose(), rho_mask_dropouts=True, keep_only_activating=True))\n",
    "\n",
    "end = datetime.now(pytz.timezone('Europe/Paris'))\n",
    "print(\"End time:\", end.strftime(\"%H:%M:%S\"))\n",
    "print(\"Running time:\", (end - start))\n",
    "\n",
    "# Note: Takes ~48mn with n_workers=24, threads_per_worker=1. BUT USES ALL 112 cores!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a51da7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modules_df = pd.DataFrame(index = range(0, len(modules)), columns = (\"Regulon\", \"TF\", \"TFTargetGenesCorrelation\", \"NbMarkers\", \"Context\", \"NES\", \"Markers\"))\n",
    "for j in range(0, len(modules)):\n",
    "    # Setting values\n",
    "    context = list(modules[j].context)\n",
    "    modules_df[\"Regulon\"].iloc[j] = modules[j].name\n",
    "    modules_df[\"TF\"].iloc[j] = modules[j].transcription_factor\n",
    "    modules_df[\"TFTargetGenesCorrelation\"].iloc[j] = context[0]\n",
    "    modules_df[\"NbMarkers\"].iloc[j] = len(set(modules[j].gene2weight))\n",
    "    modules_df[\"Context\"].iloc[j] = context[1]\n",
    "    modules_df[\"NES\"].iloc[j] = modules[j].score\n",
    "    modules_df[\"Markers\"].iloc[j] = ','.join(list(modules[j].gene2weight))\n",
    "\n",
    "modules_df = modules_df.sort_values(by='NbMarkers', ascending=False)\n",
    "modules_df.to_csv(f_modules_path, index=False, sep = \"\\t\")\n",
    "modules_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6c41a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(modules_df.TF.nunique(), \"unique TF-modules were found ( out of\",len(tf_names),\"). Modules with less than 20 markers were filtered out.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf8b0bf-d0c6-4ea4-b81e-e5e4242d54e7",
   "metadata": {},
   "source": [
    "**Note:** In the following code, I use `filter_for_annotation=False` for deactivating the pruning/filtering and producing all possible regulons. This may not be the more conservative behaviour, so feel free to deactivate it with `filter_for_annotation=True` and then play with the filtering parameters: \n",
    "- `weighted_recovery=False`\n",
    "- `rank_threshold=1500`\n",
    "- `nes_threshold=3`\n",
    "- `motif_similarity_fdr=0.001`\n",
    "- `auc_threshold=0.05`\n",
    "\n",
    "Of course, even if these parameters are set, they will have no impact on the result if `filter_for_annotation=False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cd87fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = datetime.now(pytz.timezone('Europe/Paris'))\n",
    "print(\"Start time:\", start.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "df = prune2df(dbs, modules, f_motif_path, num_workers=param_n_workers, weighted_recovery=False, rank_threshold = 1500, nes_threshold=3, motif_similarity_fdr=0.001, auc_threshold=0.05, filter_for_annotation=False)\n",
    "    \n",
    "end = datetime.now(pytz.timezone('Europe/Paris'))\n",
    "print(\"End time:\", end.strftime(\"%H:%M:%S\"))\n",
    "print(\"Running time:\", (end - start))\n",
    "\n",
    "# Note: Takes ~40mn with n_workers=24, threads_per_worker=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5804048-6035-4573-8710-af504a9d06ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f_motifs_path, sep = \"\\t\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9627e1-912d-461c-ac67-83c0b016d8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Checkpoint\n",
    "# # Reading back the data from tsv\n",
    "# ## 1. Read with multi-index headers\n",
    "# df = pd.read_csv(f_motifs_path, sep=\"\\t\", header=[0, 1], index_col=[0, 1])\n",
    "# ## 2. Transform the \"Context\" frozensets (string) into actual frozensets\n",
    "# def parse_frozenset_string(s):\n",
    "#     if isinstance(s, str) and s.startswith('frozenset'):\n",
    "#         return frozenset(ast.literal_eval(s[len('frozenset('):-1]))\n",
    "#     return s\n",
    "# df.loc[:, ('Enrichment', 'Context')] = df.loc[:, ('Enrichment', 'Context')].apply(parse_frozenset_string)\n",
    "# ## 3. Transform \"TargetGenes\" from string to list of tuples\n",
    "# def parse_list_of_tuples(s):\n",
    "#     if isinstance(s, str) and s.startswith('[') and s.endswith(']'):\n",
    "#         return ast.literal_eval(s)\n",
    "#     return s  # if it's already a list or something else\n",
    "# df.loc[:, ('Enrichment', 'TargetGenes')] = df.loc[:, ('Enrichment', 'TargetGenes')].apply(parse_list_of_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bac17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(df.index.get_level_values('TF').values)), \"regulons were kept, after pruning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbce244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for main regulons I'm looking for\n",
    "print(\"ATF4\", \"ATF4\" in df.index.get_level_values('TF').values, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a4607b-b783-4efa-b8ea-8f0652e23310",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size of Dataframe:\", len(df))\n",
    "# Check which rows have empty lists in 'TargetGenes'\n",
    "mask = df[('Enrichment', 'TargetGenes')].apply(lambda x: len(x) == 0)\n",
    "# Drop those rows\n",
    "df_filtered = df.loc[~mask]\n",
    "print(\"Size of Dataframe:\", len(df_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58e1eed-8c98-4b52-85e1-a63347491b5c",
   "metadata": {},
   "source": [
    "These \"modules\" are then combined into regulons, by taking the top NES for each TF (for main Motif, and final score of regulon). All genes are bundled together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aab324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataframe can then be converted to regulons.\n",
    "start = datetime.now(pytz.timezone('Europe/Paris'))\n",
    "print(\"Start time:\", start.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "regulons = df2regulons(df_filtered)\n",
    "\n",
    "end = datetime.now(pytz.timezone('Europe/Paris'))\n",
    "print(\"End time:\", end.strftime(\"%H:%M:%S\"))\n",
    "print(\"Running time:\", (end - start))\n",
    "\n",
    "# Note: Takes ~12mn with n_workers=24, threads_per_worker=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44659b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "regulon_df = pd.DataFrame(index = range(0, len(regulons)), columns = (\"Regulon\", \"TF\", \"TFTargetGenesCorrelation\", \"NbMarkers\", \"Motif\", \"NES\", \"Markers\"))\n",
    "for j in range(0, len(regulons)):\n",
    "    # Fixing order of set\n",
    "    context = list(regulons[j].context)\n",
    "    if(context[0].endswith(\".png\")):\n",
    "        tmp = context[0]\n",
    "        context[0] = context[1]\n",
    "        context[1] = tmp\n",
    "    # Setting values\n",
    "    regulon_df[\"Regulon\"].iloc[j] = regulons[j].name\n",
    "    regulon_df[\"TF\"].iloc[j] = regulons[j].transcription_factor\n",
    "    regulon_df[\"TFTargetGenesCorrelation\"].iloc[j] = context[0]\n",
    "    regulon_df[\"NbMarkers\"].iloc[j] = len(set(regulons[j].gene2weight))\n",
    "    regulon_df[\"Motif\"].iloc[j] = \"https://resources.aertslab.org/cistarget/motif_collections/v10nr_clust_public/logos/\" + context[1]\n",
    "    regulon_df[\"NES\"].iloc[j] = regulons[j].score\n",
    "    regulon_df[\"Markers\"].iloc[j] = ','.join(list(regulons[j].gene2weight))\n",
    "\n",
    "regulon_df = regulon_df.sort_values(by='NbMarkers', ascending=False)\n",
    "regulon_df.to_csv(f_regulons_path, index=False, sep = \"\\t\")\n",
    "regulon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43779865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for main regulons\n",
    "print(\"ATF4\", \"ATF4\" in regulon_df.TF.values, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac6c34e-9dc3-45f8-a435-69c658729b0e",
   "metadata": {},
   "source": [
    "## Phase III: Cellular regulon enrichment matrix (aka AUCell)\n",
    "\n",
    "Characterize the different cells in a single-cell transcriptomics experiment by the enrichment of the regulons. Enrichment of a regulon is measures as AUC of the recovery curve of the genes that define this regulon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3579d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now(pytz.timezone('Europe/Paris'))\n",
    "print(\"Start time:\", start.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "auc_mtx = aucell(ex_matrix.transpose(), regulons, num_workers=param_n_workers)\n",
    "\n",
    "end = datetime.now(pytz.timezone('Europe/Paris'))\n",
    "print(\"End time:\", end.strftime(\"%H:%M:%S\"))\n",
    "print(\"Running time:\", (end - start))\n",
    "\n",
    "# Note: Takes ~1h13 with n_workers=24, threads_per_worker=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b657f22-8eda-4ca8-b2fb-63bc54bd4b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_mtx.to_csv(f_regulons_aucell_path, sep = \"\\t\")\n",
    "auc_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c8362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint to regenerate the object from the file\n",
    "#auc_mtx = pd.read_csv(f_regulons_aucell_path, sep = \"\\t\", index_col = \"Cell\")\n",
    "#auc_mtx.columns.name = \"Regulon\"\n",
    "#auc_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ab567b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now(pytz.timezone('Europe/Paris'))\n",
    "print(\"Start time:\", start.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "auc_mtx_bin = binarize(auc_mtx, seed = 42, num_workers=param_n_workers)\n",
    "\n",
    "end = datetime.now(pytz.timezone('Europe/Paris'))\n",
    "print(\"End time:\", end.strftime(\"%H:%M:%S\"))\n",
    "print(\"Running time:\", (end - start))\n",
    "\n",
    "# Note: 08h40mn46 with num_workers=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5ac8ea-4999-4c73-a05c-9c2e61c1c411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# columns with all-constant values\n",
    "constant_cols = [c for c in auc_mtx.columns \n",
    "                 if np.allclose(auc_mtx[c].values, auc_mtx[c].values[0])]\n",
    "\n",
    "print(\"Number of constant columns:\", len(constant_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b942bfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarization_thresholds = auc_mtx_bin[1]\n",
    "binarization_thresholds.to_csv(f_regulons_binarization_thresholds_aucell_path, sep = \"\\t\")\n",
    "binarization_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaf52f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_mtx_bin = auc_mtx_bin[0]\n",
    "auc_mtx_bin.to_csv(f_regulons_binarized_aucell_path, sep = \"\\t\")\n",
    "auc_mtx_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a4a4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(auc_mtx_bin[\"ATF4(+)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630c7a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarization_thresholds.loc['ATF4(+)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2fa4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(auc_mtx[\"ATF4(+)\"] > binarization_thresholds.loc['ATF4(+)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5072b17d-643d-4581-9d30-f9b3068f00fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySCENIC v0.12.1",
   "language": "python",
   "name": "pyscenic_0_12_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
